{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Spanish voice: Eddy (Spanish (Spain))\n",
      "Waiting for command. Say 'detente' to trigger the action or exit.\n",
      "Calibrating for ambient noise...\n",
      "Calibration complete.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Valid speech detected.\n",
      "You said: Qué son las dns jarvis\n",
      "Calibrating for ambient noise...\n",
      "Calibration complete.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Valid speech detected.\n",
      "You said: jarvis Qué son las d\n",
      "Las \"d\" son letras del alfabeto español que se utilizan para representar un sonido consonántico en palabras.\n",
      "Calibrating for ambient noise...\n",
      "Calibration complete.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Valid speech detected.\n",
      "You said: jarvis Qué son las redes neuronales profundas\n",
      "Las redes neuronales profundas son modelos de aprendizaje automático que consisten en múltiples capas de neuronas interconectadas, diseñados para aprender representaciones complejas de datos.\n",
      "Calibrating for ambient noise...\n",
      "Calibration complete.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Valid speech detected.\n",
      "You said: una aplicación chula Pero complicada la verdad\n",
      "Calibrating for ambient noise...\n",
      "Calibration complete.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n",
      "Could not understand the audio. Please speak more clearly.\n",
      "Please speak (you have 10 seconds to start speaking)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# This while loop runs indefinitely.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mget_valid_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;66;03m# Recognize the speech using Google Speech Recognition.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m         text \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrecognize_google(audio, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mes-ES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m, in \u001b[0;36mget_valid_audio\u001b[0;34m(r, timeout, phrase_time_limit)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease speak (you have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds to start speaking)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphrase_time_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphrase_time_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m audio \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(audio, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_data\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(audio\u001b[38;5;241m.\u001b[39mframe_data) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m             \u001b[38;5;66;03m# Attempt to recognize speech (this may be slow or produce errors on low audio)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/playground/lib/python3.9/site-packages/speech_recognition/__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[1;32m    458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/playground/lib/python3.9/site-packages/speech_recognition/__init__.py:530\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[1;32m    532\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[0;32m~/.pyenv/versions/playground/lib/python3.9/site-packages/speech_recognition/__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/playground/lib/python3.9/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import time\n",
    "import pyttsx3\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize text-to-speech engine and set Spanish voice if available.\n",
    "voices = engine.getProperty('voices')\n",
    "spanish_voice_found = False\n",
    "for voice in voices:\n",
    "    if \"spanish\" in voice.name.lower():\n",
    "        engine.setProperty('voice', voice.id)\n",
    "        spanish_voice_found = True\n",
    "        print(f\"Selected Spanish voice: {voice.name}\")\n",
    "        break\n",
    "if not spanish_voice_found:\n",
    "    print(\"No specific Spanish voice found. You may need to install additional Spanish voices.\")\n",
    "\n",
    "engine.setProperty('rate', 150)\n",
    "engine.setProperty('volume', 0.8)\n",
    "\n",
    "# Command to listen for (you can customize this as needed)\n",
    "TARGET_COMMAND = \"detente\"  # for example: say \"detente\" to trigger a response\n",
    "\n",
    "def is_significant_audio(audio, threshold=500):\n",
    "    # Convert raw audio data to numpy array assuming 16-bit samples\n",
    "    # Make sure to know the sample width (bytes per sample) from your audio data\n",
    "    audio_data = np.frombuffer(audio.frame_data, dtype=np.int16)\n",
    "    rms = np.sqrt(np.mean(audio_data**2))\n",
    "    return rms > threshold\n",
    "def get_valid_audio(r, timeout=10, phrase_time_limit=None):\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Calibrating for ambient noise...\")\n",
    "        r.adjust_for_ambient_noise(source, duration=0.25)\n",
    "        print(\"Calibration complete.\")\n",
    "        while True:\n",
    "            try:\n",
    "                print(f\"Please speak (you have {timeout} seconds to start speaking)...\")\n",
    "                audio = r.listen(source, timeout=timeout, phrase_time_limit=phrase_time_limit)\n",
    "                if audio is not None and hasattr(audio, 'frame_data') and len(audio.frame_data) > 0:\n",
    "                    try:\n",
    "                        # Attempt to recognize speech (this may be slow or produce errors on low audio)\n",
    "                        text = r.recognize_google(audio)\n",
    "                        if text.strip():\n",
    "                            print(\"Valid speech detected.\")\n",
    "                            return audio\n",
    "                        else:\n",
    "                            print(\"The transcription is empty. Please speak clearly.\")\n",
    "                    except sr.UnknownValueError:\n",
    "                        print(\"Could not understand the audio. Please speak more clearly.\")\n",
    "                    except sr.RequestError as e:\n",
    "                        print(f\"Could not request results; {e}\")\n",
    "                    # if is_significant_audio(audio):\n",
    "                    #     print(\"Valid audio captured.\")\n",
    "                    #     text = r.recognize_google(audio, language=\"es-ES\")\n",
    "                    #     print(\"You said:\", text)\n",
    "                    #     # Check for the target command.\n",
    "                    #     if text.lower().strip() != TARGET_COMMAND and text.lower().strip().startswith(\"jarvis\") == False:\n",
    "                    #         print(\"Captured audio appears to be Bluff. Please speak louder or try again.\")\n",
    "                    #     else:\n",
    "                    #         return audio\n",
    "                    # else:\n",
    "                    #     print(\"Captured audio appears to be silent or only ambient noise. Please speak louder or try again.\")\n",
    "                   \n",
    "                else:\n",
    "                    print(\"Captured audio is empty. Please speak louder or try again.\")\n",
    "            except sr.WaitTimeoutError:\n",
    "                print(\"No speech detected within the timeout period. Please try again.\")\n",
    "            time.sleep(1)\n",
    "\n",
    "# Create a recognizer instance once.\n",
    "r = sr.Recognizer()\n",
    "\n",
    "print(\"Waiting for command. Say '{}' to trigger the action or exit.\".format(TARGET_COMMAND))\n",
    "# This while loop runs indefinitely.\n",
    "while True:\n",
    "    audio = get_valid_audio(r)\n",
    "    try:\n",
    "        # Recognize the speech using Google Speech Recognition.\n",
    "        text = r.recognize_google(audio, language=\"es-ES\")\n",
    "        print(\"You said:\", text)\n",
    "\n",
    "         # Check for the target command.\n",
    "        if text.lower().strip() == TARGET_COMMAND:\n",
    "            print(\"Target command received:\", TARGET_COMMAND)\n",
    "            engine.say(\"Adios\")\n",
    "            engine.runAndWait()\n",
    "            # Optionally, perform some action here.\n",
    "            # If you want to exit the loop, uncomment the next line:\n",
    "            break\n",
    "\n",
    "        if text.lower().strip().startswith(\"jarvis\"):\n",
    "            prompt = text\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini-2024-07-18\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": f\"Respond the following question: {prompt}, in just one sentence. Your name is Jarvis. Your are an Artificial Intelligence Assistant. Your answer will be only in the Spanish language.\"}\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            print(response.choices[0].message.content)\n",
    "\n",
    "            respuesta_a_decir = response.choices[0].message.content\n",
    "            \n",
    "            # Use the engine to speak back the recognized text.\n",
    "            engine.say(respuesta_a_decir)\n",
    "            engine.runAndWait()\n",
    "\n",
    "        \n",
    "        \n",
    "       \n",
    "            \n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I couldn't understand the audio.\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"API error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Say something...\")\n",
    "    audio = r.listen(source)\n",
    "\n",
    "    \n",
    "try:\n",
    "    text = r.recognize_google(audio,language=\"es-ES\")\n",
    "    \n",
    "    prompt = text\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Convert to SQL: {prompt}, just give me the SQL Query, nothing else. Return the content as a string.\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, I couldn't understand.\")\n",
    "except sr.RequestError:\n",
    "    print(\"API error.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
